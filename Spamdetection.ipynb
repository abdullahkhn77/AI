{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "0f4a37af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('spam_ham_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f95d52b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a2263936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([i for i in text if i.isalpha() or i.isspace()])\n",
    "    words = text.split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ce50bf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f972934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_count = train_labels.value_counts()['spam']\n",
    "ham_count = train_labels.value_counts()['ham']\n",
    "total_count = len(train_labels)\n",
    "\n",
    "p_spam = spam_count / total_count\n",
    "p_ham = ham_count / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "64d7c9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words = [word for email in train_data for word in email]\n",
    "\n",
    "vocabulary = set(train_words)\n",
    "\n",
    "spam_word_count = len([word for email in train_data[train_labels == 'spam'] for word in email])\n",
    "ham_word_count = len([word for email in train_data[train_labels == 'ham'] for word in email])\n",
    "\n",
    "word_probs_spam = {}\n",
    "word_probs_ham = {}\n",
    "alpha = 1\n",
    "\n",
    "for word in vocabulary:\n",
    "    word_count_spam = sum([email.count(word) for email in train_data[train_labels == 'spam']])\n",
    "    word_count_ham = sum([email.count(word) for email in train_data[train_labels == 'ham']])\n",
    "    \n",
    "    p_word_spam = (word_count_spam + alpha) / (spam_word_count + alpha * len(vocabulary))\n",
    "    p_word_ham = (word_count_ham + alpha) / (ham_word_count + alpha * len(vocabulary))\n",
    "    \n",
    "    word_probs_spam[word] = p_word_spam\n",
    "    word_probs_ham[word] = p_word_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3bc33ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(email):\n",
    "    words = preprocess(email)\n",
    "    \n",
    "    log_p_spam = np.log(p_spam)\n",
    "    log_p_ham = np.log(p_ham)\n",
    "    \n",
    "    for word in words:\n",
    "        if word in word_probs_spam:\n",
    "            log_p_spam += np.log(word_probs_spam[word])\n",
    "        else:\n",
    "            log_p_spam += np.log(alpha / (spam_word_count + alpha * len(vocabulary)))\n",
    "            \n",
    "        if word in word_probs_ham:\n",
    "            log_p_ham += np.log(word_probs_ham[word])\n",
    "        else:\n",
    "            log_p_ham += np.log(alpha / (ham_word_count + alpha * len(vocabulary)))\n",
    "    \n",
    "\n",
    "    if log_p_spam > log_p_ham:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'ham'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "7b6e8981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.975\n"
     ]
    }
   ],
   "source": [
    "accuracy = (predicted_labels == test_labels).mean()\n",
    "\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "30637ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify('''Subject: Meeting on Friday\n",
    "\n",
    "Hi all,\n",
    "\n",
    "Just a reminder that we have a meeting scheduled for Friday at 10am in the conference room. Please be on time and come prepared with your updates.\n",
    "\n",
    "Thanks,\n",
    "John''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "17402de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify('congratualations! you won a lottery')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
